{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46a9afb1100548d3a8abde20e141fd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9865cb30a2f04ea39cf55e740b844344",
              "IPY_MODEL_bdb289e8e04d4dc48e5bdf8e157ce669",
              "IPY_MODEL_9e4b0f368cda424aaa10a6d261ffe649"
            ],
            "layout": "IPY_MODEL_adec8034426f4961a19300201b55ee5d"
          }
        },
        "9865cb30a2f04ea39cf55e740b844344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a23d764f19f45f3be47f34f982bb973",
            "placeholder": "​",
            "style": "IPY_MODEL_73ecacd9a7e946f9929bfcab968573e7",
            "value": "100%"
          }
        },
        "bdb289e8e04d4dc48e5bdf8e157ce669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1685edd416c48948ae8575fee22d162",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ad190e2dd3c45d5b2122ec70e669318",
            "value": 400
          }
        },
        "9e4b0f368cda424aaa10a6d261ffe649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_705c75f6c65e450b97cb724e4d64a327",
            "placeholder": "​",
            "style": "IPY_MODEL_5e786fea501747a0ba7b81924c544e25",
            "value": " 400/400 [04:15&lt;00:00,  1.64it/s]"
          }
        },
        "adec8034426f4961a19300201b55ee5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a23d764f19f45f3be47f34f982bb973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ecacd9a7e946f9929bfcab968573e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1685edd416c48948ae8575fee22d162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad190e2dd3c45d5b2122ec70e669318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "705c75f6c65e450b97cb724e4d64a327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e786fea501747a0ba7b81924c544e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi -q"
      ],
      "metadata": {
        "_uuid": "2007b046-5005-4fe8-8069-6ab4ccea3726",
        "_cell_guid": "41b29369-539f-45ca-94de-34d53bad9108",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:20:00.553955Z",
          "iopub.execute_input": "2022-12-04T11:20:00.554470Z",
          "iopub.status.idle": "2022-12-04T11:20:14.284516Z",
          "shell.execute_reply.started": "2022-12-04T11:20:00.554380Z",
          "shell.execute_reply": "2022-12-04T11:20:14.283466Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iveRssy7KyrN",
        "outputId": "2e8f0bd7-03ca-4f92-91e8-6f7a000f0d2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.5 MB/s \n",
            "\u001b[?25h  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pretty_midi\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from tqdm.notebook import tqdm\n",
        "import collections"
      ],
      "metadata": {
        "_uuid": "46c19943-5ae7-4d27-924c-b13acc41c5a4",
        "_cell_guid": "6b1245e2-bdfe-4a79-a3dc-b6dbafbff7bd",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:20:14.288640Z",
          "iopub.execute_input": "2022-12-04T11:20:14.288928Z",
          "iopub.status.idle": "2022-12-04T11:20:22.210697Z",
          "shell.execute_reply.started": "2022-12-04T11:20:14.288896Z",
          "shell.execute_reply": "2022-12-04T11:20:22.209386Z"
        },
        "trusted": true,
        "id": "tK6uiSQYKyrS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip best_model.zip -d best_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTJXlF7_L-Bp",
        "outputId": "1388ea93-ff69-4fa2-c6ec-73b69925cbf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  best_model.zip\n",
            "   creating: best_model/best_model/\n",
            "  inflating: best_model/best_model/saved_model.pb  \n",
            "   creating: best_model/best_model/variables/\n",
            "  inflating: best_model/best_model/variables/variables.data-00000-of-00001  \n",
            "  inflating: best_model/best_model/variables/variables.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "random_seed = 42\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    print('Not running on TPU')\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "    print('batch size =', BATCH_SIZE)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "    BATCH_SIZE = 64\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "NUMBER_OF_PIANO_NOTES = 128\n",
        "SEQ_LENGTH = 100"
      ],
      "metadata": {
        "_uuid": "b923cae1-dc17-4cb1-8873-915d0028639d",
        "_cell_guid": "87339092-2f0f-47c1-abb3-299a4dc5c928",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:20:22.224798Z",
          "iopub.execute_input": "2022-12-04T11:20:22.225222Z",
          "iopub.status.idle": "2022-12-04T11:20:28.491200Z",
          "shell.execute_reply.started": "2022-12-04T11:20:22.225178Z",
          "shell.execute_reply": "2022-12-04T11:20:28.489968Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZj8c7R9KyrT",
        "outputId": "72a2baca-8ece-46bc-9406-6ac1dacd63fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  grpc://10.28.20.218:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size = 128\n",
            "REPLICAS:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Evgeny\n",
        "# Helper functions\n",
        "\n",
        "# Get all filenames from `directory`\n",
        "def get_filenames(directory):\n",
        "    filenames = []\n",
        "    for filename in os.listdir(directory):\n",
        "        f = os.path.join(directory, filename)\n",
        "        if os.path.isfile(f):\n",
        "            filenames.append(f)\n",
        "    return filenames\n",
        "\n",
        "# Load saved npz file\n",
        "def load_roll(path):\n",
        "    return np.load(path, allow_pickle=True)\n",
        "\n",
        "# Save preprocessed rolls in npz file\n",
        "def save_roll(array_map, path):\n",
        "    np.savez_compressed(path, **array_map)\n",
        "\n",
        "# Save preprocessed rolls from dataset by parts in few npz files\n",
        "def save_string_notes(directory, name):\n",
        "    filenames = get_filenames(directory)\n",
        "    saved_rolls = {}\n",
        "    files_saved = 0\n",
        "    for index, filename in enumerate(tqdm(filenames)):\n",
        "        pm = pretty_midi.PrettyMIDI(filename)\n",
        "        notes = []\n",
        "        try:\n",
        "            instrument = pm.instruments[0]\n",
        "        except IndexError:\n",
        "            print(\"Skipped\")\n",
        "            continue\n",
        "        sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
        "        if len(sorted_notes) > 100:\n",
        "            prev_start = sorted_notes[0].start\n",
        "            for note in sorted_notes:\n",
        "                notes.append(note.pitch)\n",
        "            saved_rolls[str(index)] = np.array(notes)\n",
        "        if len(saved_rolls) % 5000 == 0 and len(saved_rolls) != 0:\n",
        "            files_saved += 1\n",
        "            save_roll(saved_rolls, name)\n",
        "            print(f\"Saved file {name}\")\n",
        "            saved_rolls = {}\n",
        "    if len(saved_rolls) != 0:\n",
        "        files_saved += 1\n",
        "        save_roll(saved_rolls, name)\n",
        "        print(f\"Saved file {name}\")"
      ],
      "metadata": {
        "_uuid": "410cedaf-4faf-473e-a996-8c765b61515b",
        "_cell_guid": "288c6dd8-2200-46b1-9748-8102a894b9d1",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:20:28.492683Z",
          "iopub.execute_input": "2022-12-04T11:20:28.493092Z",
          "iopub.status.idle": "2022-12-04T11:20:28.507455Z",
          "shell.execute_reply.started": "2022-12-04T11:20:28.493049Z",
          "shell.execute_reply": "2022-12-04T11:20:28.505360Z"
        },
        "trusted": true,
        "id": "eGmIFmMKKyrT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Evgeny\n",
        "data = load_roll('/kaggle/input/maestro-merged-npz/maestro_notes.npz')"
      ],
      "metadata": {
        "_uuid": "0cc01630-9a1a-44b1-9d56-deefc6d3f59a",
        "_cell_guid": "7e5d66c2-dc48-4da1-b08b-d1fe376117d6",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:20:28.509679Z",
          "iopub.execute_input": "2022-12-04T11:20:28.511033Z",
          "iopub.status.idle": "2022-12-04T11:20:28.622892Z",
          "shell.execute_reply.started": "2022-12-04T11:20:28.510961Z",
          "shell.execute_reply": "2022-12-04T11:20:28.621790Z"
        },
        "trusted": true,
        "id": "9ZB9gs5lKyrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Evgeny\n",
        "\n",
        "all_notes = np.empty(0,)\n",
        "for item in tqdm(data.values()):\n",
        "    all_notes = np.append(all_notes, item)\n",
        "all_notes = all_notes.reshape(-1, 1)"
      ],
      "metadata": {
        "_uuid": "d64aca31-38a8-4db4-913a-a4f4171fb136",
        "_cell_guid": "1abdb8c0-fe29-46af-8974-e47761ea7d3b",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:20:28.625335Z",
          "iopub.execute_input": "2022-12-04T11:20:28.625815Z",
          "iopub.status.idle": "2022-12-04T11:20:44.438961Z",
          "shell.execute_reply.started": "2022-12-04T11:20:28.625770Z",
          "shell.execute_reply": "2022-12-04T11:20:44.437915Z"
        },
        "trusted": true,
        "id": "iJi_owjeKyrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by Evgeny\n",
        "\n",
        "full_dataset = tf.data.Dataset.from_tensor_slices(all_notes)\n",
        "train_size = int(0.8 * len(all_notes))\n",
        "test_size = int(0.2 * len(all_notes))\n",
        "\n",
        "full_dataset = full_dataset.shuffle(buffer_size=len(all_notes))\n",
        "train_dataset = full_dataset\n",
        "# train_dataset = full_dataset.take(train_size)\n",
        "# test_dataset = full_dataset.skip(train_size)"
      ],
      "metadata": {
        "_uuid": "c612d94c-f6aa-4aa8-af70-cbd5860bf5fa",
        "_cell_guid": "a02d5d61-8a8f-4503-b60b-279075a2882d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:21:10.476322Z",
          "iopub.execute_input": "2022-12-04T11:21:10.477433Z",
          "iopub.status.idle": "2022-12-04T11:21:10.599852Z",
          "shell.execute_reply.started": "2022-12-04T11:21:10.477392Z",
          "shell.execute_reply": "2022-12-04T11:21:10.598614Z"
        },
        "trusted": true,
        "id": "38weRmPrKyrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Evgeny\n",
        "\n",
        "# Function for generating (input, target) samples\n",
        "\n",
        "def create_sequences(dataset, seq_length, vocab_size):\n",
        "  seq_length = seq_length+1\n",
        "\n",
        "  windows = dataset.window(seq_length, shift=1, stride=1, drop_remainder=True)\n",
        "\n",
        "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
        "  sequences = windows.flat_map(flatten)\n",
        "\n",
        "  def scale_pitch(x):\n",
        "    x = x/[vocab_size]\n",
        "    return x\n",
        "\n",
        "  def split_labels(sequences):\n",
        "    inputs = sequences[:-1]\n",
        "    labels = sequences[-1]\n",
        "\n",
        "    return scale_pitch(inputs), labels\n",
        "\n",
        "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "_uuid": "b5468e69-f63a-4c6c-9ce0-c426960894f5",
        "_cell_guid": "11de02b5-3d6c-4183-b567-b65083cdcf5d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:21:11.763117Z",
          "iopub.execute_input": "2022-12-04T11:21:11.763399Z",
          "iopub.status.idle": "2022-12-04T11:21:11.771541Z",
          "shell.execute_reply.started": "2022-12-04T11:21:11.763372Z",
          "shell.execute_reply": "2022-12-04T11:21:11.770303Z"
        },
        "trusted": true,
        "id": "V84AXcHcKyrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Evgeny\n",
        "\n",
        "train_seq = create_sequences(train_dataset, SEQ_LENGTH, NUMBER_OF_PIANO_NOTES)\n",
        "# test_seq = create_sequences(train_dataset, SEQ_LENGTH, NUMBER_OF_PIANO_NOTES)\n",
        "\n",
        "train_loader = (train_seq\n",
        "            .repeat()\n",
        "            .batch(BATCH_SIZE, drop_remainder=True)\n",
        "            .cache()\n",
        "            .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "# test_loader = (test_seq\n",
        "#             .repeat()\n",
        "#             .batch(BATCH_SIZE, drop_remainder=True)\n",
        "#             .cache()\n",
        "#             .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "_uuid": "67dc19f0-8fd0-409e-be84-058ca557a84c",
        "_cell_guid": "7e3ed4ea-86a0-4924-8fb8-d96386c537f9",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:21:12.378307Z",
          "iopub.execute_input": "2022-12-04T11:21:12.378630Z",
          "iopub.status.idle": "2022-12-04T11:21:12.520255Z",
          "shell.execute_reply.started": "2022-12-04T11:21:12.378601Z",
          "shell.execute_reply": "2022-12-04T11:21:12.519250Z"
        },
        "trusted": true,
        "id": "VMI2jAm4KyrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "input_shape = (SEQ_LENGTH, 1)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0005)\n",
        "\n",
        "model_type = 1\n",
        "\n",
        "if model_type == 1:\n",
        "    with strategy.scope():\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.LSTM(512, input_shape=input_shape, recurrent_dropout=0.3, return_sequences=True))\n",
        "        model.add(tf.keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3))\n",
        "        model.add(tf.keras.layers.LSTM(512))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Dropout(0.3))\n",
        "        model.add(tf.keras.layers.Dense(256))\n",
        "        model.add(tf.keras.layers.Activation('relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Dropout(0.3))\n",
        "        model.add(tf.keras.layers.Dense(NUMBER_OF_PIANO_NOTES))\n",
        "        model.add(tf.keras.layers.Activation('softmax'))\n",
        "        \n",
        "else:\n",
        "    with strategy.scope():\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.LSTM(128, input_shape = input_shape, return_sequences=True))\n",
        "        model.add(tf.keras.layers.LSTM(128))\n",
        "        model.add(tf.keras.layers.Dropout(0.1))\n",
        "        model.add(tf.keras.layers.Dense(NUMBER_OF_PIANO_NOTES))\n",
        "        model.add(tf.keras.layers.Activation('softmax'))\n",
        "        \n",
        "if tpu:\n",
        "    steps_per_execution = 32\n",
        "    model.compile(loss=loss, optimizer=opt, steps_per_execution=steps_per_execution)\n",
        "else:\n",
        "    model.compile(loss=loss, optimizer=opt)\n",
        "model.summary()"
      ],
      "metadata": {
        "_uuid": "da231892-f0d3-4e76-9819-9be7ef7b4063",
        "_cell_guid": "76266a9b-1e6e-48c9-8ed6-6f09df7cd57f",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:21:13.081203Z",
          "iopub.execute_input": "2022-12-04T11:21:13.081716Z",
          "iopub.status.idle": "2022-12-04T11:21:22.195073Z",
          "shell.execute_reply.started": "2022-12-04T11:21:13.081668Z",
          "shell.execute_reply": "2022-12-04T11:21:22.194240Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmhkUIM_KyrX",
        "outputId": "254c47fc-4ba4-468f-b8fa-574613455656"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 512)          1052672   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 512)          2099200   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 512)               2099200   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,418,368\n",
            "Trainable params: 5,416,832\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "# Load model from `best_model` directory\n",
        "\n",
        "with strategy.scope():\n",
        "    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
        "    model = tf.keras.models.load_model('best_model', options=load_locally)\n",
        "    steps_per_execution = 32\n",
        "    model.compile(loss=loss, optimizer=opt, steps_per_execution=steps_per_execution)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-04T11:46:19.026065Z",
          "iopub.execute_input": "2022-12-04T11:46:19.026383Z",
          "iopub.status.idle": "2022-12-04T11:46:32.274044Z",
          "shell.execute_reply.started": "2022-12-04T11:46:19.026356Z",
          "shell.execute_reply": "2022-12-04T11:46:32.272536Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IL7GApuKyrX",
        "outputId": "a4e5b8fc-9cf8-4615-fef1-23798297e222"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "# Conditional checkpoints\n",
        "\n",
        "if tpu:\n",
        "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "    checkpoints = tf.keras.callbacks.ModelCheckpoint('tpu_checkpoints', options=save_locally)\n",
        "else:\n",
        "    checkpoints = tf.keras.callbacks.ModelCheckpoint(filepath='training_checkpoints/ckpt_{epoch}', save_weights_only=True)\n",
        "    \n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, verbose=2, restore_best_weights=True),\n",
        "\n",
        "callbacks = [\n",
        "    checkpoints,\n",
        "    es,\n",
        "]\n",
        "\n",
        "epochs = 100"
      ],
      "metadata": {
        "_uuid": "7a032e79-4183-48e4-b2dc-93233e610879",
        "_cell_guid": "be08c86b-787a-4f10-a550-2bba2d397f12",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:21:22.203613Z",
          "iopub.execute_input": "2022-12-04T11:21:22.203939Z",
          "iopub.status.idle": "2022-12-04T11:21:22.215324Z",
          "shell.execute_reply.started": "2022-12-04T11:21:22.203900Z",
          "shell.execute_reply": "2022-12-04T11:21:22.214073Z"
        },
        "trusted": true,
        "id": "Krg2YpAhKyrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "# Train model\n",
        "\n",
        "history = model.fit(\n",
        "  train_loader,\n",
        "  steps_per_epoch= len(train_dataset) // BATCH_SIZE // 10,\n",
        "  epochs=epochs,\n",
        "  callbacks=callbacks,\n",
        ")\n",
        "\n",
        "plt.plot(history.epoch, history.history['loss'], label=f'train loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "24bb4536-c6b6-4559-8b31-28cc8a8e9ce6",
        "_cell_guid": "cb44470d-3352-430a-8cb1-b42aad25e4f6",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:21:22.217371Z",
          "iopub.execute_input": "2022-12-04T11:21:22.217628Z",
          "iopub.status.idle": "2022-12-04T11:41:58.277280Z",
          "shell.execute_reply.started": "2022-12-04T11:21:22.217602Z",
          "shell.execute_reply": "2022-12-04T11:41:58.275772Z"
        },
        "trusted": true,
        "id": "37rLUKjbKyrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "# Save model\n",
        "\n",
        "with strategy.scope():\n",
        "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "    model.save('./best_model', options=save_locally)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-04T11:19:13.429980Z",
          "iopub.status.idle": "2022-12-04T11:19:13.430893Z",
          "shell.execute_reply.started": "2022-12-04T11:19:13.430642Z",
          "shell.execute_reply": "2022-12-04T11:19:13.430667Z"
        },
        "trusted": true,
        "id": "Lu7reBByKyrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil and Evgeny\n",
        "def predict_next_note(notes, keras_model, temperature) -> int:\n",
        "\n",
        "  assert temperature > 0\n",
        "\n",
        "  notes = tf.expand_dims(notes, 0)\n",
        "  predictions = keras_model.predict(notes, verbose = 0)\n",
        "  pitch_logits = predictions\n",
        "  pitch_logits /= temperature\n",
        "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
        "  while not 40 < pitch < 80:\n",
        "      pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
        "  pitch = tf.squeeze(pitch, axis=-1)\n",
        "  return int(pitch)\n",
        "\n",
        "def predict_sequence(seed, model, num_predictions, temperature):\n",
        "\n",
        "    current_sequence = seed\n",
        "    generated_sequence = []\n",
        "    for _ in tqdm(range(num_predictions)):\n",
        "      pitch = predict_next_note(current_sequence, model, temperature)\n",
        "      generated_sequence.append(pitch)\n",
        "      current_sequence = np.delete(current_sequence, 0, axis=0)\n",
        "\n",
        "      current_sequence = np.append(current_sequence, np.reshape(pitch, (-1, 1)), axis=0)\n",
        "\n",
        "    generated_sequence = np.array(generated_sequence)\n",
        "    return generated_sequence\n",
        "\n",
        "\n",
        "def notes_to_midi(notes, out_file, is_original: bool=False, velocity = 100, step = 0.2, duration = 0.4):\n",
        "\n",
        "  pm = pretty_midi.PrettyMIDI()\n",
        "  instrument = pretty_midi.Instrument(\n",
        "      program=pretty_midi.instrument_name_to_program(\n",
        "          \"Acoustic Grand Piano\")\n",
        "      )\n",
        "\n",
        "  prev_start = 0\n",
        "  for note in notes:\n",
        "    start = float(prev_start + step)\n",
        "    end = float(start + duration)\n",
        "    if is_original is True:\n",
        "        input_pitch=int(note * NUMBER_OF_PIANO_NOTES)\n",
        "    else:\n",
        "        input_pitch = int(note)\n",
        "    note = pretty_midi.Note(\n",
        "        velocity=velocity,\n",
        "        pitch=input_pitch,\n",
        "        start=start,\n",
        "        end=end,\n",
        "    )\n",
        "    instrument.notes.append(note)\n",
        "    prev_start = start\n",
        "\n",
        "  pm.instruments.append(instrument)\n",
        "  pm.write(out_file)\n",
        "  return pm\n",
        "\n",
        "def midi_to_notes(path):\n",
        "    saved_rolls = 0\n",
        "    pm = pretty_midi.PrettyMIDI(path)\n",
        "    notes = []\n",
        "    try:\n",
        "        instrument = pm.instruments[0]\n",
        "    except IndexError:\n",
        "        print(\"Skipped\")\n",
        "        return None\n",
        "    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
        "    if len(sorted_notes) > 100:\n",
        "        prev_start = sorted_notes[0].start\n",
        "        for note in sorted_notes:\n",
        "            notes.append(note.pitch)\n",
        "        saved_rolls = np.array(notes)\n",
        "    if len(saved_rolls) % 5000 == 0 and len(saved_rolls) != 0:\n",
        "        files_saved += 1\n",
        "    return saved_rolls"
      ],
      "metadata": {
        "_uuid": "6650a8cf-1897-4307-a10e-dee2b4d6ffe2",
        "_cell_guid": "309e338c-35a3-4842-a60c-2787296d36fd",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:19:13.432440Z",
          "iopub.status.idle": "2022-12-04T11:19:13.433088Z",
          "shell.execute_reply.started": "2022-12-04T11:19:13.432837Z",
          "shell.execute_reply": "2022-12-04T11:19:13.432861Z"
        },
        "trusted": true,
        "id": "1iEZyVbrKyrZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "# seed = midi_to_notes('/kaggle/input/mozart-v2/Wolfgang Amadeus Mozart/Mozart Wolfgang Amadeus Fantasia in C minor K.475 Ui9pyxdVX6Y.mid')\n",
        "# seed = seed[100:200].reshape(-1, 1) / NUMBER_OF_PIANO_NOTES\n",
        "\n",
        "seed = np.random.randint(low=40, high=100, size=(100, 1)) / NUMBER_OF_PIANO_NOTES\n",
        "\n",
        "original = notes_to_midi(seed, f'original_test.mid', is_original=True) \n",
        "generated = notes_to_midi(predict_sequence(seed, model, num_predictions = 400, temperature = 1), f'generated_test.mid', step = 0.25, duration = 0.4)"
      ],
      "metadata": {
        "_uuid": "2a9b3758-066d-4372-aeda-f0e978c10c7d",
        "_cell_guid": "72157cd0-c24a-4803-b25d-a6d847469757",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:19:13.434685Z",
          "iopub.status.idle": "2022-12-04T11:19:13.435775Z",
          "shell.execute_reply.started": "2022-12-04T11:19:13.435567Z",
          "shell.execute_reply": "2022-12-04T11:19:13.435586Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "46a9afb1100548d3a8abde20e141fd67",
            "9865cb30a2f04ea39cf55e740b844344",
            "bdb289e8e04d4dc48e5bdf8e157ce669",
            "9e4b0f368cda424aaa10a6d261ffe649",
            "adec8034426f4961a19300201b55ee5d",
            "9a23d764f19f45f3be47f34f982bb973",
            "73ecacd9a7e946f9929bfcab968573e7",
            "a1685edd416c48948ae8575fee22d162",
            "1ad190e2dd3c45d5b2122ec70e669318",
            "705c75f6c65e450b97cb724e4d64a327",
            "5e786fea501747a0ba7b81924c544e25"
          ]
        },
        "id": "Z_hBJGgCKyra",
        "outputId": "5d6ef68c-0474-4f86-92d6-82c49c6e4d40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/400 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46a9afb1100548d3a8abde20e141fd67"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Done by: Kamil\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_for_folder(path, seq_length):\n",
        "  for filename in os.listdir(path):\n",
        "    f = os.path.join(path, filename)\n",
        "    if os.path.isfile(f):\n",
        "        try:\n",
        "            seed = midi_to_notes(f)\n",
        "        except:\n",
        "            continue\n",
        "        start = np.random.randint(50, 150)\n",
        "        seed = seed[start:start+100].reshape(-1, 1) / NUMBER_OF_PIANO_NOTES\n",
        "        if seed.shape[0] < 100:\n",
        "            print(f\"Discarded {f.split(' ')[-1]} {seed.shape}\")\n",
        "            continue\n",
        "        else:\n",
        "            now = datetime.now()\n",
        "            current_time = now.strftime(\"_%H_%M_%S\")\n",
        "            print(f'Predicting {f}')\n",
        "            name = f.split(' ')[-1].split('.')[0]\n",
        "            generated = notes_to_midi(predict_sequence(seed, model, num_predictions = seq_length, temperature = 1), f\"1_GENERATED{current_time}_{name}.mid\")\n",
        "            generated = notes_to_midi(predict_sequence(seed, model, num_predictions = seq_length, temperature = 2), f\"2_GENERATED{current_time}_{name}.mid\")\n",
        "\n",
        "\n",
        "## TEST PURPOSES ##\n",
        "## Function for generating music with length `seq_length` for temperatures 1 and 2,\n",
        "## based on some random moment in music located in `path`\n",
        "generate_for_folder(path=\"/test\", seq_length=200)"
      ],
      "metadata": {
        "_uuid": "6f533313-0226-4776-a620-896da4be14c7",
        "_cell_guid": "07c9b5e4-7095-476e-a46c-196dafa65add",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-12-04T11:19:13.437170Z",
          "iopub.status.idle": "2022-12-04T11:19:13.438274Z",
          "shell.execute_reply.started": "2022-12-04T11:19:13.437983Z",
          "shell.execute_reply": "2022-12-04T11:19:13.438012Z"
        },
        "trusted": true,
        "id": "htPV9QQCKyra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}